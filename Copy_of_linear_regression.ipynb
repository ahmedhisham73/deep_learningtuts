{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of linear_regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+KdYUBl8DVyG9nUNYfHbC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedhisham73/deep_learningtuts/blob/master/Copy_of_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvjW2Xn5xbBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44uLoZwhxlB6",
        "colab_type": "text"
      },
      "source": [
        "Linear regression is an attractive model because the representation is so simple.\n",
        "\n",
        "The representation is a linear equation that combines a specific set of input values (x) the solution to which is the predicted output for that set of input values (y). As such, both the input values (x) and the output value are numeric.\n",
        "\n",
        "The linear equation assigns one scale factor to each input value or column, called a coefficient and represented by the capital Greek letter Beta (B). One additional coefficient is also added, giving the line an additional degree of freedom (e.g. moving up and down on a two-dimensional plot) and is often called the intercept or the bias coefficient.\n",
        "\n",
        "For example, in a simple regression problem (a single x and a single y), the form of the model would be:\n",
        "\n",
        "y = B0 + B1*x\n",
        "\n",
        "In higher dimensions when we have more than one input (x), the line is called a plane or a hyper-plane. The representation therefore is the form of the equation and the specific values used for the coefficients (e.g. B0 and B1 in the above example).\n",
        "\n",
        "It is common to talk about the complexity of a regression model like linear regression. This refers to the number of coefficients used in the model.\n",
        "\n",
        "When a coefficient becomes zero, it effectively removes the influence of the input variable on the model and therefore from the prediction made from the model (0 * x = 0). This becomes  relevant if you look at regularization methods that change the learning algorithm to reduce the complexity of regression models by putting pressure on the absolute size of the coefficients, driving some to zero.\n",
        "\n",
        "Now that we understand the representation used for a linear regression model, let’s review some ways that we can learn this representation from data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka2_skhUxt0Y",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression Learning the Model\n",
        "\n",
        "Learning a linear regression model means estimating the values of the coefficients used in the representation with the data that we have available.\n",
        "\n",
        "In this section we will take a brief look at four techniques to prepare a linear regression model. This is not enough information to implement them from scratch, but enough to get a flavor of the computation and trade-offs involved.\n",
        "\n",
        "There are many more techniques because the model is so well studied. Take note of Ordinary Least Squares because it is the most common method used in general. Also take note of Gradient Descent as it is the most common technique taught in machine learning classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPWrHXsYxz7S",
        "colab_type": "text"
      },
      "source": [
        "1. Simple Linear Regression\n",
        "\n",
        "With simple linear regression when we have a single input, we can use statistics to estimate the coefficients.\n",
        "\n",
        "This requires that you calculate statistical properties from the data such as means, standard deviations, correlations and covariance. All of the data must be available to traverse and calculate statistics.\n",
        "\n",
        "This is fun as an exercise in excel, but not really useful in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G7RXsN7x6vL",
        "colab_type": "text"
      },
      "source": [
        "Making Predictions with Linear Regression\n",
        "\n",
        "Given the representation is a linear equation, making predictions is as simple as solving the equation for a specific set of inputs.\n",
        "\n",
        "Let’s make this concrete with an example. Imagine we are predicting weight (y) from height (x). Our linear regression model representation for this problem would be:\n",
        "\n",
        "y = B0 + B1 * x1\n",
        "\n",
        "or\n",
        "\n",
        "weight =B0 +B1 * height\n",
        "\n",
        "Where B0 is the bias coefficient and B1 is the coefficient for the height column. We use a learning technique to find a good set of coefficient values. Once found, we can plug in different height values to predict the weight.\n",
        "\n",
        "For example, lets use B0 = 0.1 and B1 = 0.5. Let’s plug them in and calculate the weight (in kilograms) for a person with the height of 182 centimeters.\n",
        "\n",
        "weight = 0.1 + 0.5 * 182\n",
        "\n",
        "weight = 91.1\n",
        "\n",
        "You can see that the above equation could be plotted as a line in two-dimensions. The B0 is our starting point regardless of what height we have. We can run through a bunch of heights from 100 to 250 centimeters and plug them to the equation and get weight values, creating our line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZkZ1zsyD0J",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/02/Sample-Height-vs-Weight-Linear-Regression.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG_raisOyOSs",
        "colab_type": "text"
      },
      "source": [
        "Preparing Data For Linear Regression\n",
        "\n",
        "Linear regression is been studied at great length, and there is a lot of literature on how your data must be structured to make best use of the model.\n",
        "\n",
        "As such, there is a lot of sophistication when talking about these requirements and expectations which can be intimidating. In practice, you can uses these rules more as rules of thumb when using Ordinary Least Squares Regression, the most common implementation of linear regression.\n",
        "\n",
        "Try different preparations of your data using these heuristics and see what works best for your problem.\n",
        "\n",
        "    Linear Assumption. Linear regression assumes that the relationship between your input and output is linear. It does not support anything else. This may be obvious, but it is good to remember when you have a lot of attributes. You may need to transform data to make the relationship linear (e.g. log transform for an exponential relationship).\n",
        "    Remove Noise. Linear regression assumes that your input and output variables are not noisy. Consider using data cleaning operations that let you better expose and clarify the signal in your data. This is most important for the output variable and you want to remove outliers in the output variable (y) if possible.\n",
        "    Remove Collinearity. Linear regression will over-fit your data when you have highly correlated input variables. Consider calculating pairwise correlations for your input data and removing the most correlated.\n",
        "    Gaussian Distributions. Linear regression will make more reliable predictions if your input and output variables have a Gaussian distribution. You may get some benefit using transforms (e.g. log or BoxCox) on you variables to make their distribution more Gaussian looking.\n",
        "    Rescale Inputs: Linear regression will often make more reliable predictions if you rescale input variables using standardization or normalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INK0T4nsyPA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3c7d1af3-4ba7-47db-c92e-dfa484d6ecd5"
      },
      "source": [
        "\n",
        "\t\n",
        "# Standalone simple linear regression example\n",
        "from math import sqrt\n",
        " \n",
        "# Calculate root mean squared error\n",
        "def rmse_metric(actual, predicted):\n",
        "\tsum_error = 0.0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tprediction_error = predicted[i] - actual[i]\n",
        "\t\tsum_error += (prediction_error ** 2)\n",
        "\tmean_error = sum_error / float(len(actual))\n",
        "\treturn sqrt(mean_error)\n",
        " \n",
        "# Evaluate regression algorithm on training dataset\n",
        "def evaluate_algorithm(dataset, algorithm):\n",
        "\ttest_set = list()\n",
        "\tfor row in dataset:\n",
        "\t\trow_copy = list(row)\n",
        "\t\trow_copy[-1] = None\n",
        "\t\ttest_set.append(row_copy)\n",
        "\tpredicted = algorithm(dataset, test_set)\n",
        "\tprint(predicted)\n",
        "\tactual = [row[-1] for row in dataset]\n",
        "\trmse = rmse_metric(actual, predicted)\n",
        "\treturn rmse\n",
        " \n",
        "# Calculate the mean value of a list of numbers\n",
        "def mean(values):\n",
        "\treturn sum(values) / float(len(values))\n",
        " \n",
        "# Calculate covariance between x and y\n",
        "def covariance(x, mean_x, y, mean_y):\n",
        "\tcovar = 0.0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tcovar += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "\treturn covar\n",
        " \n",
        "# Calculate the variance of a list of numbers\n",
        "def variance(values, mean):\n",
        "\treturn sum([(x-mean)**2 for x in values])\n",
        " \n",
        "# Calculate coefficients\n",
        "def coefficients(dataset):\n",
        "\tx = [row[0] for row in dataset]\n",
        "\ty = [row[1] for row in dataset]\n",
        "\tx_mean, y_mean = mean(x), mean(y)\n",
        "\tb1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n",
        "\tb0 = y_mean - b1 * x_mean\n",
        "\treturn [b0, b1]\n",
        " \n",
        "# Simple linear regression algorithm\n",
        "def simple_linear_regression(train, test):\n",
        "\tpredictions = list()\n",
        "\tb0, b1 = coefficients(train)\n",
        "\tfor row in test:\n",
        "\t\tyhat = b0 + b1 * row[0]\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn predictions\n",
        " \n",
        "# Test simple linear regression\n",
        "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
        "rmse = evaluate_algorithm(dataset, simple_linear_regression)\n",
        "print('RMSE: %.3f' % (rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.1999999999999995, 1.9999999999999996, 3.5999999999999996, 2.8, 4.3999999999999995]\n",
            "RMSE: 0.693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FB7JUkMzVB9",
        "colab_type": "text"
      },
      "source": [
        " Predict Insurance\n",
        "\n",
        "We now know how to implement a simple linear regression model.\n",
        "\n",
        "Let’s apply it to the Swedish insurance dataset.\n",
        "\n",
        "This section assumes that you have downloaded the dataset to the file insurance.csv and it is available in the current working directory.\n",
        "\n",
        "We will add some convenience functions to the simple linear regression from the previous steps.\n",
        "\n",
        "Specifically a function to load the CSV file called load_csv(), a function to convert a loaded dataset to numbers called str_column_to_float(), a function to evaluate an algorithm using a train and test set called train_test_split() a function to calculate RMSE called rmse_metric() and a function to evaluate an algorithm called evaluate_algorithm().\n",
        "\n",
        "The complete example is listed below.\n",
        "\n",
        "A training dataset of 60% of the data is used to prepare the model and predictions are made on the remaining 40%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehC5NHQx1XAu",
        "colab_type": "text"
      },
      "source": [
        "1. Calculate Mean and Variance\n",
        "\n",
        "The first step is to estimate the mean and the variance of both the input and output variables from the training data.\n",
        "\n",
        "The mean of a list of numbers can be calculated as\n",
        "\n",
        "mean(x) = sum(x) / count(x)\n",
        "\n",
        "\t\n",
        "mean(x) = sum(x) / count(x)\n",
        "\n",
        "\n",
        "\n",
        "2\n",
        "3\n",
        "\t\n",
        "# Calculate the mean value of a list of numbers\n",
        "def mean(values):\n",
        "\treturn sum(values) / float(len(values))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  variance = sum( (x - mean(x))^2 )\n",
        "\n",
        "\n",
        "  1\n",
        "2\n",
        "3\n",
        "\t\n",
        "# Calculate the variance of a list of numbers\n",
        "def variance(values, mean):\n",
        "\treturn sum([(x-mean)**2 for x in values])\n",
        "\n",
        "\n",
        "\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPkVEUXG1NMm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0a9794bd-a1a1-48c0-b371-6f93c8ed911f"
      },
      "source": [
        "\n",
        "\t\n",
        "# Estimate Mean and Variance\n",
        " \n",
        "# Calculate the mean value of a list of numbers\n",
        "def mean(values):\n",
        "\treturn sum(values) / float(len(values))\n",
        " \n",
        "# Calculate the variance of a list of numbers\n",
        "def variance(values, mean):\n",
        "\treturn sum([(x-mean)**2 for x in values])\n",
        " \n",
        "# calculate mean and variance\n",
        "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
        "x = [row[0] for row in dataset]\n",
        "y = [row[1] for row in dataset]\n",
        "mean_x, mean_y = mean(x), mean(y)\n",
        "var_x, var_y = variance(x, mean_x), variance(y, mean_y)\n",
        "print('x stats: mean=%.3f variance=%.3f' % (mean_x, var_x))\n",
        "print('y stats: mean=%.3f variance=%.3f' % (mean_y, var_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x stats: mean=3.000 variance=10.000\n",
            "y stats: mean=2.800 variance=8.800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGzGIrxR124w",
        "colab_type": "text"
      },
      "source": [
        " 2. Calculate Covariance\n",
        "\n",
        "The covariance of two groups of numbers describes how those numbers change together.\n",
        "\n",
        "Covariance is a generalization of correlation. Correlation describes the relationship between two groups of numbers, whereas covariance can describe the relationship between two or more groups of numbers.\n",
        "\n",
        "Additionally, covariance can be normalized to produce a correlation value.\n",
        "\n",
        "Nevertheless, we can calculate the covariance between two variables as follows:\n",
        "\n",
        "covariance = sum((x(i) - mean(x)) * (y(i) - mean(y)))\n",
        "1\n",
        "\t\n",
        "covariance = sum((x(i) - mean(x)) * (y(i) - mean(y)))\n",
        "\n",
        "# Calculate covariance between x and y\n",
        "def covariance(x, mean_x, y, mean_y):\n",
        "\tcovar = 0.0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tcovar += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "\treturn covar\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXQDhVtB2BCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad4b53d1-9bc5-4710-b71f-83cf27d5f0cf"
      },
      "source": [
        "# Calculate the mean value of a list of numbers\n",
        "def mean(values):\n",
        "\treturn sum(values) / float(len(values))\n",
        " \n",
        "# Calculate covariance between x and y\n",
        "def covariance(x, mean_x, y, mean_y):\n",
        "\tcovar = 0.0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tcovar += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "\treturn covar\n",
        " \n",
        "# calculate covariance\n",
        "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
        "x = [row[0] for row in dataset]\n",
        "y = [row[1] for row in dataset]\n",
        "mean_x, mean_y = mean(x), mean(y)\n",
        "covar = covariance(x, mean_x, y, mean_y)\n",
        "print('Covariance: %.3f' % (covar))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Covariance: 8.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TQCUkwZ2I9q",
        "colab_type": "text"
      },
      "source": [
        "3. Estimate Coefficients\n",
        "\n",
        "We must estimate the values for two coefficients in simple linear regression.\n",
        "\n",
        "The first is B1 which can be estimated as:\n",
        "B1 = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 )\n",
        "1\n",
        "\t\n",
        "B1 = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 )\n",
        "\n",
        "We have learned some things above and can simplify this arithmetic to:\n",
        "B1 = covariance(x, y) / variance(x)\n",
        "1\n",
        "\t\n",
        "B1 = covariance(x, y) / variance(x)\n",
        "\n",
        "We already have functions to calculate covariance() and variance().\n",
        "\n",
        "Next, we need to estimate a value for B0, also called the intercept as it controls the starting point of the line where it intersects the y-axis.\n",
        "\n",
        "\n",
        "B0 = mean(y) - B1 * mean(x)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEnR29Dp2Lf5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f97a9d75-4d91-4950-f5f2-a78abbebacc4"
      },
      "source": [
        "# Calculate the mean value of a list of numbers\n",
        "def mean(values):\n",
        "\treturn sum(values) / float(len(values))\n",
        " \n",
        "# Calculate covariance between x and y\n",
        "def covariance(x, mean_x, y, mean_y):\n",
        "\tcovar = 0.0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tcovar += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "\treturn covar\n",
        " \n",
        "# Calculate the variance of a list of numbers\n",
        "def variance(values, mean):\n",
        "\treturn sum([(x-mean)**2 for x in values])\n",
        " \n",
        "# Calculate coefficients\n",
        "def coefficients(dataset):\n",
        "\tx = [row[0] for row in dataset]\n",
        "\ty = [row[1] for row in dataset]\n",
        "\tx_mean, y_mean = mean(x), mean(y)\n",
        "\tb1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n",
        "\tb0 = y_mean - b1 * x_mean\n",
        "\treturn [b0, b1]\n",
        " \n",
        "# calculate coefficients\n",
        "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
        "b0, b1 = coefficients(dataset)\n",
        "print('Coefficients: B0=%.3f, B1=%.3f' % (b0, b1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: B0=0.400, B1=0.800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnQ3LZ_u2dYQ",
        "colab_type": "text"
      },
      "source": [
        "4. Make Predictions\n",
        "\n",
        "The simple linear regression model is a line defined by coefficients estimated from training data.\n",
        "\n",
        "Once the coefficients are estimated, we can use them to make predictions.\n",
        "\n",
        "The equation to make predictions with a simple linear regression model is as follows:\n",
        "y = b0 + b1 * x\n",
        "1\n",
        "\t\n",
        "y = b0 + b1 * x\n",
        "\n",
        "Below is a function named simple_linear_regression() that implements the prediction equation to make predictions on a test dataset. It also ties together the estimation of the coefficients on training data from the steps above.\n",
        "\n",
        "The coefficients prepared from the training data are used to make predictions on the test data, which are then returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbmgw3jM2itm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def simple_linear_regression(train, test):\n",
        "\tpredictions = list()\n",
        "\tb0, b1 = coefficients(train)\n",
        "\tfor row in test:\n",
        "\t\tyhat = b0 + b1 * row[0]\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn predictions\n",
        "\n",
        "\t\n",
        "def simple_linear_regression(train, test):\n",
        "\tpredictions = list()\n",
        "\tb0, b1 = coefficients(train)\n",
        "\tfor row in test:\n",
        "\t\tyhat = b0 + b1 * row[0]\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q49yLEKB2rx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ca4bfd06-b7d9-42ea-b8f8-4880fe4a74f9"
      },
      "source": [
        "\n",
        "\t\n",
        "# Standalone simple linear regression example\n",
        "from math import sqrt\n",
        " \n",
        "# Calculate root mean squared error\n",
        "def rmse_metric(actual, predicted):\n",
        "\tsum_error = 0.0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tprediction_error = predicted[i] - actual[i]\n",
        "\t\tsum_error += (prediction_error ** 2)\n",
        "\tmean_error = sum_error / float(len(actual))\n",
        "\treturn sqrt(mean_error)\n",
        " \n",
        "# Evaluate regression algorithm on training dataset\n",
        "def evaluate_algorithm(dataset, algorithm):\n",
        "\ttest_set = list()\n",
        "\tfor row in dataset:\n",
        "\t\trow_copy = list(row)\n",
        "\t\trow_copy[-1] = None\n",
        "\t\ttest_set.append(row_copy)\n",
        "\tpredicted = algorithm(dataset, test_set)\n",
        "\tprint(predicted)\n",
        "\tactual = [row[-1] for row in dataset]\n",
        "\trmse = rmse_metric(actual, predicted)\n",
        "\treturn rmse\n",
        " \n",
        "# Calculate the mean value of a list of numbers\n",
        "def mean(values):\n",
        "\treturn sum(values) / float(len(values))\n",
        " \n",
        "# Calculate covariance between x and y\n",
        "def covariance(x, mean_x, y, mean_y):\n",
        "\tcovar = 0.0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tcovar += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "\treturn covar\n",
        " \n",
        "# Calculate the variance of a list of numbers\n",
        "def variance(values, mean):\n",
        "\treturn sum([(x-mean)**2 for x in values])\n",
        " \n",
        "# Calculate coefficients\n",
        "def coefficients(dataset):\n",
        "\tx = [row[0] for row in dataset]\n",
        "\ty = [row[1] for row in dataset]\n",
        "\tx_mean, y_mean = mean(x), mean(y)\n",
        "\tb1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n",
        "\tb0 = y_mean - b1 * x_mean\n",
        "\treturn [b0, b1]\n",
        " \n",
        "# Simple linear regression algorithm\n",
        "def simple_linear_regression(train, test):\n",
        "\tpredictions = list()\n",
        "\tb0, b1 = coefficients(train)\n",
        "\tfor row in test:\n",
        "\t\tyhat = b0 + b1 * row[0]\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn predictions\n",
        " \n",
        "# Test simple linear regression\n",
        "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
        "rmse = evaluate_algorithm(dataset, simple_linear_regression)\n",
        "print('RMSE: %.3f' % (rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.1999999999999995, 1.9999999999999996, 3.5999999999999996, 2.8, 4.3999999999999995]\n",
            "RMSE: 0.693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaQjJKUEzV5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7abdc2d8-85d7-4741-9fd8-8b716b50a3a5"
      },
      "source": [
        "from random import seed\n",
        "from random import randrange\n",
        "from csv import reader\n",
        "from math import sqrt\n",
        " \n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        " \n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        " \n",
        "# Split a dataset into a train and test set\n",
        "def train_test_split(dataset, split):\n",
        "\ttrain = list()\n",
        "\ttrain_size = split * len(dataset)\n",
        "\tdataset_copy = list(dataset)\n",
        "\twhile len(train) < train_size:\n",
        "\t\tindex = randrange(len(dataset_copy))\n",
        "\t\ttrain.append(dataset_copy.pop(index))\n",
        "\treturn train, dataset_copy\n",
        " \n",
        "# Calculate root mean squared error\n",
        "def rmse_metric(actual, predicted):\n",
        "\tsum_error = 0.0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tprediction_error = predicted[i] - actual[i]\n",
        "\t\tsum_error += (prediction_error ** 2)\n",
        "\tmean_error = sum_error / float(len(actual))\n",
        "\treturn sqrt(mean_error)\n",
        " \n",
        "# Evaluate an algorithm using a train/test split\n",
        "def evaluate_algorithm(dataset, algorithm, split, *args):\n",
        "\ttrain, test = train_test_split(dataset, split)\n",
        "\ttest_set = list()\n",
        "\tfor row in test:\n",
        "\t\trow_copy = list(row)\n",
        "\t\trow_copy[-1] = None\n",
        "\t\ttest_set.append(row_copy)\n",
        "\tpredicted = algorithm(train, test_set, *args)\n",
        "\tactual = [row[-1] for row in test]\n",
        "\trmse = rmse_metric(actual, predicted)\n",
        "\treturn rmse\n",
        " \n",
        "# Calculate the mean value of a list of numbers\n",
        "def mean(values):\n",
        "\treturn sum(values) / float(len(values))\n",
        " \n",
        "# Calculate covariance between x and y\n",
        "def covariance(x, mean_x, y, mean_y):\n",
        "\tcovar = 0.0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tcovar += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "\treturn covar\n",
        " \n",
        "# Calculate the variance of a list of numbers\n",
        "def variance(values, mean):\n",
        "\treturn sum([(x-mean)**2 for x in values])\n",
        " \n",
        "# Calculate coefficients\n",
        "def coefficients(dataset):\n",
        "\tx = [row[0] for row in dataset]\n",
        "\ty = [row[1] for row in dataset]\n",
        "\tx_mean, y_mean = mean(x), mean(y)\n",
        "\tb1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n",
        "\tb0 = y_mean - b1 * x_mean\n",
        "\treturn [b0, b1]\n",
        " \n",
        "# Simple linear regression algorithm\n",
        "def simple_linear_regression(train, test):\n",
        "\tpredictions = list()\n",
        "\tb0, b1 = coefficients(train)\n",
        "\tfor row in test:\n",
        "\t\tyhat = b0 + b1 * row[0]\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn predictions\n",
        " \n",
        "# Simple linear regression on insurance dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = '/content/insurance.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# evaluate algorithm\n",
        "split = 0.6\n",
        "rmse = evaluate_algorithm(dataset, simple_linear_regression, split)\n",
        "print('RMSE: %.3f' % (rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 33.630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtmQxU0dz5pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Multivariate Linear Regression\n",
        "\n",
        "Linear regression is a technique for predicting a real value.\n",
        "\n",
        "Confusingly, these problems where a real value is to be predicted are called regression problems.\n",
        "\n",
        "Linear regression is a technique where a straight line is used to model the relationship between input and output values. In more than two dimensions, this straight line may be thought of as a plane or hyperplane.\n",
        "\n",
        "Predictions are made as a combination of the input values to predict the output value.\n",
        "\n",
        "Each input attribute (x) is weighted using a coefficient (b), and the goal of the learning algorithm is to discover a set of coefficients that results in good predictions (y).\n",
        "y = b0 + b1 * x1 + b2 * x2 + ...\n",
        "1\n",
        "\t\n",
        "y = b0 + b1 * x1 + b2 * x2 + ...\n",
        "\n",
        "Coefficients can be found using stochastic gradient descent."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC5WmtLe3vwy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC-A68mN3wkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c21432a8-ea59-40fc-dcba-fe4d3bfaa287"
      },
      "source": [
        "from random import seed\n",
        "from random import randrange\n",
        "from csv import reader\n",
        "from math import sqrt\n",
        " \n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        " \n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        " \n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tfor i in range(len(dataset[0])):\n",
        "\t\tcol_values = [row[i] for row in dataset]\n",
        "\t\tvalue_min = min(col_values)\n",
        "\t\tvalue_max = max(col_values)\n",
        "\t\tminmax.append([value_min, value_max])\n",
        "\treturn minmax\n",
        " \n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        " \n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor i in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        " \n",
        "# Calculate root mean squared error\n",
        "def rmse_metric(actual, predicted):\n",
        "\tsum_error = 0.0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tprediction_error = predicted[i] - actual[i]\n",
        "\t\tsum_error += (prediction_error ** 2)\n",
        "\tmean_error = sum_error / float(len(actual))\n",
        "\treturn sqrt(mean_error)\n",
        " \n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\trmse = rmse_metric(actual, predicted)\n",
        "\t\tscores.append(rmse)\n",
        "\treturn scores\n",
        " \n",
        "# Make a prediction with coefficients\n",
        "def predict(row, coefficients):\n",
        "\tyhat = coefficients[0]\n",
        "\tfor i in range(len(row)-1):\n",
        "\t\tyhat += coefficients[i + 1] * row[i]\n",
        "\treturn yhat\n",
        " \n",
        "# Estimate linear regression coefficients using stochastic gradient descent\n",
        "def coefficients_sgd(train, l_rate, n_epoch):\n",
        "\tcoef = [0.0 for i in range(len(train[0]))]\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tfor row in train:\n",
        "\t\t\tyhat = predict(row, coef)\n",
        "\t\t\terror = yhat - row[-1]\n",
        "\t\t\tcoef[0] = coef[0] - l_rate * error\n",
        "\t\t\tfor i in range(len(row)-1):\n",
        "\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
        "\t\t\t# print(l_rate, n_epoch, error)\n",
        "\treturn coef\n",
        " \n",
        "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
        "def linear_regression_sgd(train, test, l_rate, n_epoch):\n",
        "\tpredictions = list()\n",
        "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
        "\tfor row in test:\n",
        "\t\tyhat = predict(row, coef)\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn(predictions)\n",
        " \n",
        "# Linear Regression on wine quality dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = '/content/insurance.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# normalize\n",
        "minmax = dataset_minmax(dataset)\n",
        "normalize_dataset(dataset, minmax)\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "l_rate = 0.01\n",
        "n_epoch = 50\n",
        "scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [0.11035418618029173, 0.11388916034529066, 0.17826020082536442, 0.08331123156491674, 0.11977097127113807]\n",
            "Mean RMSE: 0.121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On4Tnidk4e4S",
        "colab_type": "text"
      },
      "source": [
        "The core of many machine learning algorithms is optimization.\n",
        "\n",
        "Optimization algorithms are used by machine learning algorithms to find a good set of model parameters given a training dataset.\n",
        "\n",
        "The most common optimization algorithm used in machine learning is stochastic gradient descent.\n",
        "\n",
        "In this tutorial, you will discover how to implement stochastic gradient descent to optimize a linear regression algorithm from scratch with Python.\n",
        "\n",
        "After completing this tutorial, you will know:\n",
        "\n",
        "    How to estimate linear regression coefficients using stochastic gradient descent.\n",
        "    How to make predictions for multivariate linear regression.\n",
        "    How to implement linear regression with stochastic gradient descent to make predictions on new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYE2Ubrl39LZ",
        "colab_type": "text"
      },
      "source": [
        "A k value of 5 was used for cross-validation, giving each fold 4,898/5 = 979.6 or just under 1000 records to be evaluated upon each iteration. A learning rate of 0.01 and 50 training epochs were chosen with a little experimentation.\n",
        "\n",
        "You can try your own configurations and see if you can beat my score.\n",
        "\n",
        "Running this example prints the scores for each of the 5 cross-validation folds then prints the mean RMSE.\n",
        "\n",
        "We can see that the RMSE (on the normalized dataset) is 0.126, lower than the baseline value of 0.148 if we just predicted the mean (using the Zero Rule Algorithm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqwrS3F24KSr",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDDa94bH4WI_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}